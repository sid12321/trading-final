# @package _global_

workflow_cls: evorl.algorithms.a2c.A2CWorkflow

num_envs: 4

normalize_obs: false
rollout_length: 128 # train_batch_size = rollout_length * num_envs = 512
gae_lambda: 0.95
discount: 0.99

total_timesteps: 1000000

num_eval_envs: 16
eval_interval: 50
eval_episodes: 16 # should be divided by num_eval_envs

loss_weights:
  actor_loss: 1.0
  critic_loss: 0.5
  actor_entropy: -0.01

optimizer:
  lr: 0.0003
  grad_clip_norm: 10.0 # set 0 or null to turn-off

agent_network:
  actor_hidden_layer_sizes: [256, 256]
  critic_hidden_layer_sizes: [256, 256]
  policy_obs_key: null
  value_obs_key: null
