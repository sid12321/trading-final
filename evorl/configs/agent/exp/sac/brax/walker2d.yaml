# @package _global_

defaults:
  - /agent/sac
  - _self_

# Note: unlike brax, we don"t change reward_scale
# reward_scaling: 5

num_envs: 128
normalize_obs: true
rollout_length: 1
discount: 0.997
total_timesteps: 10000000
fold_iters: 256

batch_size: 128

optimizer:
  lr: 0.0006

num_updates_per_iter: 16

random_timesteps: 0
learning_start_timesteps: 8192

num_eval_envs: 128
eval_episodes: 128 # should be divided by num_eval_envs
eval_interval: 256 # unit: num of iterations

checkpoint:
  save_interval_steps: 2560

tags: ["batch-brax"]
