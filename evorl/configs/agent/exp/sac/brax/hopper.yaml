# @package _global_

defaults:
  - /agent/sac
  - _self_

# Note: unlike brax, we don"t use reward_scale=30

num_envs: 128
normalize_obs: true
rollout_length: 2
discount: 0.997
total_timesteps: 10000000
fold_iters: 256

batch_size: 512

optimizer:
  lr: 0.0006

num_updates_per_iter: 64

random_timesteps: 0
learning_start_timesteps: 8192 # init timesteps from the init agent

num_eval_envs: 128
eval_episodes: 128 # should be divided by num_eval_envs
eval_interval: 256 # unit: num of iterations

checkpoint:
  save_interval_steps: 2560

tags: ["batch-brax"]
