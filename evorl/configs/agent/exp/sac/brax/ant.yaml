# @package _global_

defaults:
  - /agent/sac
  - _self_

# Note: unlike brax, we don"t change reward_scale

num_envs: 256
normalize_obs: true
rollout_length: 2
discount: 0.95
total_timesteps: 10000000
fold_iters: 128

batch_size: 512

optimizer:
  lr: 0.0006

num_updates_per_iter: 32

random_timesteps: 0
learning_start_timesteps: 8192

num_eval_envs: 128
eval_episodes: 128 # should be divided by num_eval_envs
eval_interval: 128 # unit: num of iterations

checkpoint:
  save_interval_steps: 1280

tags: ["batch-brax"]
