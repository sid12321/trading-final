# @package _global_

defaults:
  - /agent/erl/cemrl
  - _self_

total_episodes: 20000

actor_update_interval: 1 # not needed since we apply it over #num_learning_offspring actors

random_timesteps: 25600
warmup_iters: 10 # steps that only learn by CEM

pop_size: 10
num_learning_offspring: 5

num_elites: 5
cov_eps:
  init: 1e-3
  final: 1e-5
  decay: 0.05

fitness_with_exploration: false
episodes_for_fitness: 1 # must be devided by num_envs
num_rl_updates_per_iter: 4096 # fastpbrl use #sampled_timesteps for #updates, here we set a fixed #update by using around half of the maximum #updates (10*1000)/2

num_eval_envs: 128
eval_episodes: 128 # should be divided by num_eval_envs
eval_interval: 10
